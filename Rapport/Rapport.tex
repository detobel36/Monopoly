\documentclass[letterpaper]{article}

\usepackage{natbib,alifexi}
\usepackage{amsmath}
\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{blkarray}
\usepackage{tikz}
\usetikzlibrary{automata, positioning}

\newcommand{\colornode}[1][]{\node[state,
	    align=center,
	    text=gray!40!black,
	    draw=gray,
	    fill=gray!20!white,{#1}]}
\newcommand{\bigcolornode}[1][]{\node[state,
	    align=center,
	    text=gray!40!black,
	    draw=gray,
	    fill=gray!20!white,
	    text width=1.7cm,{#1}]}

\newcommand{\drawedge}{\draw[every loop, line width=0.4mm, fill=gray, draw=gray]}

\newcommand*{\fullref}[1]{\hyperref[{#1}]{\autoref*{#1} \nameref*{#1}}}


\title{Etude du Monopoly via les chaînes de Markov}
\author{Rémy Detobel\\
Mickael Randour\\
\mbox{}\\
Université Libre de Bruxelles, Bruxelles, Belgique \\
rdetobel@ulb.ac.be}


% =-=-=-=-=-=-=-=-= TODO GENERAL =-=-=-=-=-=-=-=-=
% - Bibliographie (revoir l'affichage, la mise en page)
% - Résultats
% - Conclusion


\begin{document}
\maketitle

\begin{abstract}
  Modélisation et étude du Monopoly à travers les chaînes de Markov.
  Les concepts principaux de ce modèle qu'est une chaîne de Markov,
  seront présentés et expliqués.  Les différents choix permettant 
  d'adapter le Monopoly afin qu'il puisse être modélisé comme une chaîne 
  de Markov seront également expliqués.  Enfin, une description de 
  l'application et des résultats récupérés par l'implémentation de cette 
  modélisation sera également faite et permettra de déterminer les cases 
  les plus fréquentés ainsi que les cases les plus rentables.
\end{abstract}

%%%%%%%%%%%%%% SECTION %%%%%%%%%%%%%%
\section{Introduction}
  Contrairement aux idées reçues, chaque case du Monopoly n'a pas la même
  probabilité d'être visitée.  Il est donc intéressant d'étudier quels sont
  les cases les plus fréquentés mais également quels seraient les cases
  les plus rentables.  Dans cette idée, il est possible de modéliser
  le Monopoly à travers les chaînes de Markov.  Mais avant cela, il est 
  important de bien définir les chaînes de Markov ainsi que leurs propriétés.
  Les explications concernant ce modèle sont en grande partie basées 
  sur le cours de \citet{COURS}.
  Pour pouvoir modéliser le Monopoly comme étant une chaîne de Markov, 
  les règles du jeu doivent être clairement définies et des choix doivent
  être faits.  Ceux-ci seront donc expliqués et justifiés dans cet article.
  Les résultats trouvés suite à cette modélisation seront présentés afin
  de trouver, au final, les cases les plus visitées mais également les cases
  les plus rentables.
  % TODO ajouter des informations à l'intro (peut être plus conséquent)
  
  
%%%%%%%%%%%%%% SECTION %%%%%%%%%%%%%%
\section{Approche théorique}
  
  \subsection{Les chaînes de Markov}
    \label{def_chaine_markov}
    Une chaîne de Markov est une structure de données qui permet de modéliser l'évolution
    de l'état d'un système aléatoire.  Les chaînes de Markov sont basées sur le 
    fait que l'état actuel du système dépend uniquement de l'état précédent.
    Cette propriété peut être appelé ``propriété de Markov''.  Une chaîne de
    Markov est donc composée d'états et de liens entre ses différents états caractérisés
    par une certaine probabilité de passer d'un état A à un état B.
    Cette probabilité sera décrite plus en détail dans le point \ref{probabilite}.
    Il est possible de représenter une chaîne de Markov de plusieurs manières différentes.
    Dans la litérature (comme par exemple dans le cours \citet{COURS}), on utilisera 
    plus souvant la notation matricel, qui définit la chaîne de Markov $\mathcal{M}$ 
    tel que:
    $$\mathcal{M} = (S, \mathbf{P}, \iota_{init})$$
    Où $S$ représente l'ensemble de tous les états possibles, $\mathbf{P}$ une matrice $S \times S$
    où chaque élément est compris entre 0 et 1 et où cette valeur représente la probabilité 
    de passer d'un état à un autre (respectivement, l'état correspondant à la ligne et à la colonne).
    On appelera cette matrice $\mathbf{P}$ la \textit{matrice de transition}.
    $\iota_{init}$ est une matrice colonne où chaque ligne représente un état et la valeur
    associée représente la probabilité de commencer par cet état.  On peut retrouver d'autres
    variables dans la litérature (comme $AP$ et $L$ par exemple pour associer des propositions 
    atomiques aux états) mais celles-ci ne seront pas utiles dans cet article.
    Il est également possible de représenter une chaîne de Markov sous forme
    d'un graphe dirigé où chaque noeud représente un état et chaque arrête est pondéré
    en fonction de la probabilité de passer d'un état à un autre.
    Nottons également que les chaînes de Markov peuvent être utilisée
    dans un temps discret ou dans un temps continu.  Cependant, la modélisation
    du Monopoly n'inclura pas de temps continu et cet article traitera donc uniquement
    du temps discret.
    % TODO voir pour définir AP et L en 2 phrases
    
  \subsection{Exemple de chaîne de Markov}
    \label{exemple}
    Afin d'illustrer les notions liées aux chaînes de Markov, cet article se 
    basera sur un exemple représentant les différents état que peut avoir 
    un avion.  On va donc ici considérer qu'un avion pourra avoir 6 états 
    différents: \textit{en vol} (noté \textit{vol}), \textit{attérissage} 
    (noté \textit{att.}), \textit{décollage} (noté \textit{dec.}), 
    \textit{au sol}, \textit{contrôle} (noté \textit{ctr.})
    et \textit{hors service} (noté \textit{h.s.}).
    On va considérer que lors de l'\textit{attérissage}, il y a une chance sur 
    3 pour qu'un voyant indique au pilote qu'un \textit{contrôle} est 
    nécessaire. On remarque également qu'il y a une chance sur 10 que 
    l'avion ne passe pas le \textit{contrôle} et soit considéré comme 
    \textit{hors service}.  On considèrera également que tous les avions commencent
    avec l'état \textit{au sol}.
    
    \subsubsection{Représentation matriciel}
      Comme vu au point \ref{def_chaine_markov}, il est possible de représenter une
      chaine de Markov comme étant:
      $$\mathcal{M} = (S, \mathbf{P}, \iota_{init})$$
      Pour notre exemple on aura donc:
      $$S = \{vol, dec., att., sol, ctr., h.s.\} $$
      $$ \mathbf{P} = 
	\begin{blockarray}{ccccccc}
	& vol & dec. & att. & sol & ctr. & h.s. \\
	  \begin{block}{c(cccccc)}
	    vol  & 0 & 0 & 1 & 0    & 0   & 0    \\
	    dec. & 1 & 0 & 0 & 0    & 0   & 0    \\
	    att. & 0 & 0 & 0 & 2/3  & 1/3 & 0    \\
	    sol  & 0 & 1 & 0 & 0    & 0   & 0    \\
	    ctr. & 0 & 0 & 0 & 9/10 & 0   & 1/10 \\
	    h.s. & 0 & 0 & 0 & 0    & 0   & 1    \\
	  \end{block}
	\end{blockarray}
      $$
      $$\iota_{init} = 
	\begin{blockarray}{cc}
	  \begin{block}{( c ) c}
	    0 & vol \\
	    0 & dec.\\
	    0 & att.\\
	    1 & sol\\
	    0 & ctr.\\
	    0 & h.s.\\
	  \end{block}
	\end{blockarray}
      $$
      
    \subsubsection{Représentation graphique}
      Il est également possible de représenter cette chaîne de Markov comme
      état un graphe dirigé (cfr point \ref{def_chaine_markov}):
      \begin{center}
	\begin{tikzpicture}
	  % Draw the states
	  \colornode[text width=1.7cm] (vol) {En vol};
	  
	  \colornode[below left=of vol] (att) {Attérissage};
	  \bigcolornode[below right=of vol] (dec) {Décollage};
	  
	  \bigcolornode[below right=of att] (sol) {Au sol};

	  \bigcolornode[below left=of sol] (ctr) {Contrôle};
	  \colornode[right=of ctr] (hs) {Hors service};

	  % Connect the states with arrows
	  \drawedge
	    (vol) edge[bend right, auto=right] node {1} (att)
	    (dec) edge[bend right, auto=right] node {1} (vol)
	    (sol) edge[bend right, auto=right] node {1} (dec)
	    (att) edge[bend right, auto=right] node {2/3} (sol)
	    (att) edge[bend right, auto=right] node {1/3} (ctr)
	    (ctr) edge[bend right, auto=left] node {9/10} (sol)
	    (ctr) edge[bend right, auto=right] node {1/10} (hs)
	    (hs) edge[loop right] node {1} (hs);
	  \draw [->, line width=0.4mm, fill=gray, draw=gray] (1.6,-5.4) -- (sol);
	\end{tikzpicture}
      \end{center}
    
  \subsection{Probabilité}
    \label{probabilite}
    La notion de probabilité peut se définir de plusieurs manières différentes 
    et de nombreux ouvrages (comme par exemple celui de \citet{IP}) décrivent 
    de manière très détaillé la notion de probabilité.  Dans ces ouvrages, on
    traite souvant des espaces de probabilité, qui demandent une approche très 
    abstraite et rigoureuses.  Cependant dans cet article, l'approche
    fréquentielle inspirée des statitistiques est suffisante.
    On définit donc la probabilité d'un événement aléatoire par la limite
    de la fréquence d'occurence d'un événement pour un nombre d'expériences
    tendant vers l'infini.  De manière plus formel, on peut décrire ce
    comportement comme $X$ étant une expérience aléatoire ayant
    $$X_i \mid i \in I $$
    pour résultats possibles, avec $I$ un ensemble d'indices (qui peuvent 
    être fini, infini dénombrable ou infini non-dénombrable).  On définit
    la probabilité du résultat $X_i$ pour $i \in I$ par:
    $$\lim_{n \to \infty}\frac {X_i(n)}n,$$
    avec $X_i(n)$, le nombre d'occurences du résultat $X_i$ lors de
    $n$ itérations de l'expérience $X$.  On note cette valeur
    $\mathbb P[X = X_i]$, si cette limite existe.
    % QUESTION Randour: ajouter ceci ?
    % Remarque : il est important de demander que la limite existe, par exemple 
    % si le nombre d'occurrences est sous la forme $X(n) = n\cos(n)$, on remarque 
    % qu'il est impossible de définir une probabilité, alors qu'une fréquence a un sens.
    
  \subsection{Simuler les changements d'état}
    Une chaîne de Markov permet donc d'estimer la probabilité de l'état
    futur d'un système uniquement en se basant sur l'état actuel du système.
    Dans cette idée, la matrice de transition $\mathbf{P}$ représente tous les
    déplacements d'une unité possibles.  Si maintenant on veut connaitre
    les états accèssibles depuis notre état actuel après deux unités de temps,
    il suffit d'élevé la matrice de transition au carré.  Si l'on reprend
    notre exemple, on aura donc:
    \begin{align*}
    \mathbf{P}^2 &= 
      \begin{pmatrix}
	0 & 0 & 1 & 0    & 0   & 0    \\
	1 & 0 & 0 & 0    & 0   & 0    \\
	0 & 0 & 0 & 2/3  & 1/3 & 0    \\
	0 & 1 & 0 & 0    & 0   & 0    \\
	0 & 0 & 0 & 9/10 & 0   & 1/10 \\
	0 & 0 & 0 & 0    & 0   & 1    \\
      \end{pmatrix}^2\\
      &= 
      \begin{pmatrix}
        0 & 0    & 0 & 2/3  & 1/3 & 0    \\
	0 & 0    & 1 & 0    & 0   & 0    \\
	0 & 2/3  & 0 & 3/10 & 0   & 1/30 \\
	1 & 0    & 0 & 0    & 0   & 0    \\
	0 & 9/10 & 0 & 0    & 0   & 1/10 \\
	0 & 0    & 0 & 0    & 0   & 1    \\
      \end{pmatrix}
    \end{align*}
    % TODO A voir si c'est clair
    On remarque donc qu'après 2 déplacements depuis le première état (première
    ligne), il sera possible d'atteindre le 4 et 5\up{ème} état (avec 
    respectivement une probabilité de $2/3$ et $1/3$).  Ce comportement est
    très simple à voir dans cette exemple, car l'état succédant l'état 1 est
    obligatoirement le 3\up{ème} état.  Il est donc normal qu'après 2 tours,
    on retrouve les probabilités de déplacement du troisième état.
    
  \subsection{Propriété d'une chaîne de Markov}
    On peut remarquer que la somme de tous les éléments de chaque ligne de la
    matrice de transition font $1$.  Ce phénomène peut également être vu
    sur la représentation graphique de la chaîne de Markov où la somme de chaque
    arrête quittant un noeud (un état donc) vaut $1$.  Par exemple, si l'on se
    concentre sur l'état \textit{att.} (sur la représentation matriciel il s'agit donc 
    de la 3\up{ème} ligne), on a bien: $2/3 + 1/3 + 0$ qui vaut bien $1$.  De manière 
    plus formel, cette caractéristique peut être notée tel que pour une matrice
    $\mathcal{M}$ (définie au point \ref{def_chaine_markov}) et pour tout état $s \in S$:
    $$\sum\limits_{s' \in S} \mathbf{P}(s, s') = 1$$
    Où $\mathbf{P}(s, s')$ représente la probabilité (présente dans la matrice de
    transition) de passer de l'état $s$ à l'état $s'$.  Cette caractéristique est
    toujours vrai par défintion d'une chaîne de Markov mais également par définition
    d'une probabilité.
    En effet, la matrice $\mathbf{P}$ contient toutes les rélations possibles entre
    tous les états du système ($S \times S$).  Une ligne représente donc toutes les 
    relations possibles entre un état (définit par la ligne actuelle) et tous les autres
    état du système (les $S$ colonnes).  La probabilité de passer de l'état actuel
    à n'importe quel autre état du système est donc égal à $1$ (par définition d'une probabilité).
    Avec ce même raisonnement, il est logique de se rendre compte que la matrice
    de distribution initiale possède les mêmes caractéristiques:
    $$\sum\limits_{s \in S} \iota_{init}(s) = 1$$
    
  \subsection{Notation des chaînes des Markov}
    Certaines chaînes de Markov ont différentes structures et certains
    sous-ensembles d'états possèdent des caractéristiques particulières.
    Ces ensembles sont donc notés via différentes abréviations.  Ces différentes
    abréviations et concepts sont utilisés dans plusieurs articles scientifiques
    comme par exemple dans le livre de \citet{ModelChecking} ou dans le cours
    \citet{COURS}.  Pour formaliser ces différents concepts, on définit 
    une chaîne de Markov $\mathcal{M}(S, \mathbf{P}, \iota_{init})$ 
    (comme vu au point \ref{def_chaine_markov}) ainsi qu'un sous-ensemble $T$ de $S$.
    
    % TODO texte introductif
    \subsubsection{Fortement connexe}
      Ce sous-ensemble $T$ sera définit comme \textit{fortement connexe} si
      pour chaque pair d'état $(s, t)$ tel que $s, t \in T$, il existe un
      chemin $s_0, s_1, ..., s_n$ tel que $s_i \in T$ pour $0 \leq i \leq n$, 
      $s_0 = s$ et $s_n = t$.\\
      Dans l'exemple présenté au point \ref{exemple}, une composante fortement
      connexe pourrait être: $\{vol, att., dec., sol\}$
      
    \subsubsection{Composante fortement connexe}
      Une composante fortemment connexe est abrégé \textit{SCC} (``Strongly
      Conntected Component'' en anglais) et est définit tel que pour un état
      $s \in S$, sa compostante fortement connexe est le plus grand ensemble
      $U$ au sens de l'inclusion tel que $s \in U$ et $U$ est fortement connexe.\\
      Nottons au passage, que $S$ est partitionnable en $\{U_1, \ldots, U_n\}$ tel que :
      \begin{itemize}
	\item $\forall i \in \{1, \ldots, n\} : U_i$ est connexe ;
	\item $\forall (i, j) \in \{1, \ldots, n\}^2 : i \neq j \Rightarrow U_i \cap U_j = \emptyset$.
      \end{itemize}
      
    \subsubsection{BSCC}
      \label{bscc}
      \textit{BSCC} signifie ``Bottom Strongly Connected Component'' en anglais.
      Une \textit{BSCC} de $\mathcal{M}$ est une composante fortement connexe 
      (SCC) $T$ tel que aucun état en dehors de $T$ n'est pas accèssible.  De manière
      plus formel, cela signifie que $\forall i \in T$:
      $$\sum\limits_{t \in T} \mathbf{P}(i, t) = 1$$
      Il est important de noter qu'une fois que l'état actuel se retrouve dans une
      BSCC, il est impossible d'en sortir.  Cela signifie qu'après un nombre fini
      ou infini dénombrable d'étape, on sera toujours dans un état présent dans le BSCC
      pour autant que l'on ai commencé dans ce BSCC.\\
      L'exemple du point \ref{exemple} a pour seul BSCC: $\{h.s.\}$ (qui 
      est donc uniquement composé d'un seul état).
  
  \subsection{Distribution stationnaire}
    Comme vu au point \ref{bscc}, la probabilité de se retrouver dans un état
    présent dans un BSCC après un nombre fini ou infini dénombrable d'étape est
    toujours de 1 (pour autant que l'on ai commencé dans un état lui même présent
    dans ce BSCC).  Remarquons cependant que chaque état présent dans ce BSCC n'a 
    pas la même probabilité d'être visité.  En effet, certains états seront 
    visités plus souvent que d'autres.
    On définit la distribution stationnaire comme étant un vecteur de probabilité
    $\mathbf{v}$ tel que:
    $$\mathbf{v}\mathbf{P} = \mathbf{v}$$
    Et où pour chaque élément $\mathbf{v}_i \in \mathbf{v}, \mathbf{v}_i \in [0, 1]$.
    Par définition d'un BSCC, la somme des probabilités de chaque état doit valoir 1
    (car après un nombre fini ou infini dénombrable d'étape, on sera toujours dans
    état présent dans ce même BSCC), on peut donc écrire:
    $$\sum\limits_{\mathbf{v}_i \in \mathbf{v}} \mathbf{v}_i = 1$$
    
    \subsubsection{Caclul de la distribution stationnaire}
      Nous allons définir le calcul de la distribution stationnaire à travers 
      un exemple.  Malheureusement, il n'est pas possible de reprendre l'exemple
      présenté en point \ref{exemple} car le calcul de la distribution stationnaire 
      de son BSCC est trivial (vu qu'il n'en exsite qu'un seul) et vaut 1.
      Nous allons donc légèrement modifier cet exemple en considèrant maintenant 
      que tous les avions \textit{hors service} seront tous réparés (avec une 
      probabilité de 1 donc) et à nouveau mis dans l'état \textit{au sol}.  
      Ce nouvel exemple sera noté $\mathcal{M}'$.
      La matrice de transition de $\mathcal{M}'$ sera donc:
      $$ \mathbf{P} = 
	\begin{blockarray}{ccccccc}
	& vol & dec. & att. & sol & ctr. & h.s. \\
	  \begin{block}{c(cccccc)}
	    vol  & 0 & 0 & 1 & 0    & 0   & 0    \\
	    dec. & 1 & 0 & 0 & 0    & 0   & 0    \\
	    att. & 0 & 0 & 0 & 2/3  & 1/3 & 0    \\
	    sol  & 0 & 1 & 0 & 0    & 0   & 0    \\
	    ctr. & 0 & 0 & 0 & 9/10 & 0   & 1/10 \\
	    h.s. & 0 & 0 & 0 & 1    & 0   & 0    \\
	  \end{block}
	\end{blockarray}
      $$
      Et sa représentation graphique:
      \begin{center}
	\begin{tikzpicture}
	  % Draw the states
	  \colornode[text width=1.7cm] (vol) {En vol};
	  
	  \colornode[below left=of vol] (att) {Attérissage};
	  \bigcolornode[below right=of vol] (dec) {Décollage};
	  
	  \bigcolornode[below right=of att] (sol) {Au sol};

	  \bigcolornode[below left=of sol] (ctr) {Contrôle};
	  \colornode[right=of ctr] (hs) {Hors service};

	  % Connect the states with arrows
	  \drawedge
	    (vol) edge[bend right, auto=right] node {1} (att)
	    (dec) edge[bend right, auto=right] node {1} (vol)
	    (sol) edge[bend right, auto=right] node {1} (dec)
	    (att) edge[bend right, auto=right] node {2/3} (sol)
	    (att) edge[bend right, auto=right] node {1/3} (ctr)
	    (ctr) edge[bend right, auto=left] node {9/10} (sol)
	    (ctr) edge[bend right, auto=right] node {1/10} (hs)
	    (hs) edge[bend right] node [left] {1} (sol);
	  \draw [->, line width=0.4mm, fill=gray, draw=gray] (1.6,-5.4) -- (sol);
	\end{tikzpicture}
      \end{center}
      Le BSCC de la matrice $\mathcal{M}'$ contiendra donc tous les états de cette 
      chaîne de Markov.  Le calcul de la distribution stationnaire nous permet
      de savoir la probabilité qu'a chaque état (présent dans ce BSCC) d'être visité.
      La distribution stationnaire de la matrice $\mathcal{M}'$, sera donc définit
      par le vecteur $\mathbf{v}$ tel que:
      \begin{align*}
	\mathbf{v} . \mathbf{P} &= \mathbf{v}\\
	\begin{blockarray}{(c)}
	  \mathbf{v}_{vol}\\
	  \mathbf{v}_{dec.}\\
	  \mathbf{v}_{att.}\\
	  \mathbf{v}_{sol}\\
	  \mathbf{v}_{ctr.}\\
	  \mathbf{v}_{h.s.}
	\end{blockarray}^T .
	\begin{blockarray}{(cccccc)}
	    0 & 0 & 1 & 0    & 0   & 0    \\
	    1 & 0 & 0 & 0    & 0   & 0    \\
	    0 & 0 & 0 & 2/3  & 1/3 & 0    \\
	    0 & 1 & 0 & 0    & 0   & 0    \\
	    0 & 0 & 0 & 9/10 & 0   & 1/10 \\
	    0 & 0 & 0 & 1    & 0   & 0    \\
	\end{blockarray}
	&= 
	\begin{blockarray}{(c)}
	  \mathbf{v}_{vol}\\
	  \mathbf{v}_{dec.}\\
	  \mathbf{v}_{att.}\\
	  \mathbf{v}_{sol}\\
	  \mathbf{v}_{ctr.}\\
	  \mathbf{v}_{h.s.}
	\end{blockarray}^T
      \end{align*}
      et où:
      $$\mathbf{v}_{vol} + \mathbf{v}_{dec.} + \mathbf{v}_{att.} + \mathbf{v}_{sol} + 
	\mathbf{v}_{ctr.} + \mathbf{v}_{h.s.} = 1$$
      Calculer une équation où les inconnues se trouve de part et d'autre de l'égalité
      n'est pas une chose aisée, notons également que peu de solveur acceptent les 
      problèmes écrit de cette façon.  Il est donc possible de réécrire cette égalité
      de plusieurs manières différentes.  Le livre  ``Introduction to Probability'' 
      de \cite{IP} nous en présentes quelques une dans le chapitre 11.
      Dans cet article nous utiliserons une matrice identité $\mathbf{I}$ tel que:
      \begin{align*}
       \mathbf{v} . \mathbf{P} &= \mathbf{v}\\
       \mathbf{v} . \mathbf{P} &= \mathbf{v} . \mathbf{I}\\
       \mathbf{v} . \mathbf{P} - \mathbf{v}. \mathbf{I} &= 0\\
       \mathbf{v} . (\mathbf{P} - \mathbf{I}) &= 0
      \end{align*}
      On se retrouve donc avec un système d'équation plus ``classique'' (où chaque 
      équation correspond à une constante):
      $$\begin{blockarray}{(c)}
	  \mathbf{v}_{vol}\\
	  \mathbf{v}_{dec.}\\
	  \mathbf{v}_{att.}\\
	  \mathbf{v}_{sol}\\
	  \mathbf{v}_{ctr.}\\
	  \mathbf{v}_{h.s.}
	\end{blockarray}^T .
	\begin{blockarray}{(cccccc)}
	    -1 & 0  & 1  & 0    & 0   & 0    \\
	    1  & -1 & 0  & 0    & 0   & 0    \\
	    0  & 0  & -1 & 2/3  & 1/3 & 0    \\
	    0  & 1  & 0  & -1   & 0   & 0    \\
	    0  & 0  & 0  & 9/10 & -1  & 1/10 \\
	    0  & 0  & 0  & 1    & 0   & -1    \\
	\end{blockarray}
	= 
	\begin{blockarray}{(c)}
	  0\\
	  0\\
	  0\\
	  0\\
	  0\\
	  0
	\end{blockarray}^T$$
      Qui peut être décomposé en sous-équation:
      \begin{align*}
       \mathbf{v}_{vol} . -1 &+ \mathbf{v}_{dec.} . 1 &+ &\mathbf{v}_{att.} . 0 &+ ... &+ \mathbf{v}_{h.s} . 0 &= 0\\
       \mathbf{v}_{vol} . 0 &+ \mathbf{v}_{dec.} . -1 &+ &\mathbf{v}_{att.} . 0 &+ ... &+ \mathbf{v}_{h.s} . 0 &= 0\\
       & & ... & & & &= 0\\
       \mathbf{v}_{vol} . 0 &+ \mathbf{v}_{dec.} . 0 &+ &\mathbf{v}_{att.} . 0 &+ ... &+ \mathbf{v}_{h.s} . -1 &= 0\\
      \end{align*}
      Toutes les equations définissant la distribution stationnaire ont donc  la même forme:
      $$\mathbf{v}_{vol} + \mathbf{v}_{dec.} + \mathbf{v}_{att.} + \mathbf{v}_{sol} + 
	\mathbf{v}_{ctr.} + \mathbf{v}_{h.s.} = 1$$
      La résolution de ce système d'équation nous permet donc de trouver la distribution
      stationnaire de notre chaîne de Markov $\mathcal{M}'$ qui vaut donc:
      \begin{align*}
       \mathbf{v} &= (\mathbf{v}_{vol}; \mathbf{v}_{dec.}; \mathbf{v}_{att.}; \mathbf{v}_{sol}; 
	  \mathbf{v}_{ctr.}; \mathbf{v}_{h.s.})\\
      \mathbf{v} &= (0,229; 0,229; 0,229; 0,229; 0,0763; 0,0076)
      \end{align*}
      
  
%%%%%%%%%%%%%% SECTION %%%%%%%%%%%%%%
\section{Modélisation}

  \subsection{Plateau de jeux}
    Les plateaux de jeux peuvent être modélisé comme des chaînes de Markov.  En effet, on peut 
    voir la position d'un point comme l'état d'un système.  Dans ce type de jeu (comme 
    par exemple le jeu de l'oie) la position du pion dépendra seulement de la case où il 
    se trouvait précédemment et du nombre de case qu'il doit parcourrir (dû par exemple 
    au lancement d'un dé ou à l'indication présente sur la case où le pion se trouvait).
    Les jeux de plateau où le déplacement des pionts n'influancent pas directement la 
    victoire d'un joueur et où chaque case du plateau de jeu peut être visité tout 
    au long de la partie, peuvent être vu comme des BSCC.  
  
  \subsection{Modélisation}
    Le Monopoly peut en effet être vu comme une chaîne de Markov.  En effet, comme décrit
    ci-dessus, on peut voir la position d'un point comme l'état d'un système.  Plus 
    concrètement, chaque case sera numérotée et représentera un état de la chaîne de Markov.
    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.4]{./Images/Monopoly.png}
	\caption{Numéroation du Monopoly \citep{IMG_Monopoly}}
    \end{figure}
    
    Chaque déplacement du piont (c'est-à-dire à chaque fois que l'on lance le dé) sera 
    traduit par un changement d'état.
    Dans un premier temps, on modélise donc le Monopoly par 40 cases où chaque case est
    relié aux $6*n-(n-1)$ cases suivante à partir de la case $n-1$, où $n$ est le 
    nombre de dé.  Dans le cas précis des règles du Monopoly, chaque case pourra 
    donc accéder à 11 autres cases.  En effet, le résultat le plus petit pouvant être 
    produit par $n$ dés est de $n$ (tous les dé à 1).
    On devra donc élminer toutes les $n-1$ cases juste après la case actuelle et le résultat
    le plus grand pouvant être produit par $n$ dés est de $6*n$ (pour un dé à 6 faces).
    \begin{center}
      \begin{tikzpicture}
        \colornode[text width=1cm] at (0, 0) (c0) {Départ};
        \colornode[text width=0.7cm] at (1.5, 0) (c1) {Case 1};
        \colornode[text width=0.7cm] at (3, 0) (c2) {Case 2};
        \colornode[text width=1cm] at (5.5, 0) (cx) {...};
        \colornode[text width=0.7cm] at (7, 0) (c12) {Case 12};
        
        \drawedge
	  (c0) edge[bend left] node {} (c2)
	  (c0) edge[bend left] node {} (cx)
	  (c0) edge[bend left] node {} (c12)
	  (c1) edge[bend right] node {} (cx)
	  (c1) edge[bend right] node {} (c12);
        
      \end{tikzpicture}
    \end{center}
    Cependant, certaines cases ont un comportement particulier comme
    par exemple la case ``aller en prison'' sur laquelle on ne peut pas rester; en effet,
    celle-ci nous redirige directement dans la prison.  La case ``chance'' et ``caisse de
    communauté'' sont égalements des cas particuliers qui font que le Monopoly n'est pas 
    équiréparti.
    
  \subsection{Répartition des dés}
    \label{repart_des}
    Lorsque l'on lance $n$ dés, la somme des valeurs de chaque dés n'a pas la même probabilité
    d'apparaitre.  En effet, lorsque l'on lance 2 dés, il y a 3 manière différentes de formé
    un 4 (à savoir: $3+1$, $2+2$ et $1+3$) alors qu'il n'y a qu'une seule manière de formé un 
    2 (à savoir: $1+1$), comme illustré par la figure \ref{tableau_repartition_des}.
    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.4]{./Images/RepartitionDes.jpg}
	\caption{Répartition des nombres formés avec 2 dés \citep{IMG_Des}}
      \label{tableau_repartition_des}
    \end{figure}
    Cette répartition peut être généralisé de la manière suivante:
    $$\sum\limits_{k=0}^{(s-n)/6} (-1)^k \begin{pmatrix}n \\ k\end{pmatrix} 
      \begin{pmatrix}s-6k-1 \\n-1\end{pmatrix}$$
    Source: %\url{http://villemin.gerard.free.fr/Wwwgvmm/Identite/Identxx2.htm\#formule}\\
    Où $n$ est le nombre de dés et $s$ le nombre que l'on désire former.  Cette equation
    a été construite suite à la décomposition en polynome permettant de calculer des
    réparition.\\
    En effet, en prennant par exemple le polynome $3x + 5x^2 + x^3$ et en le mettant au 
    carré, on va récupérer toutes les combinaissons possibles:
    \begin{align*}
     &(3x \times 3x) + (3x \times 5x^2) + (3x \times x^3) +\\
     &(5x^2 \times 5x^2) + (5x^2 \times x^3) + (x^3 \times x^3)\\
     &= (9x^2) + (15x^3) + (3x^4) + (25x^4) + (5x^5) + (x^6)\\
     &= x^6 + 5x^5 + 28x^4 + 15x^3 + 9x^2
    \end{align*}
    Ce calcul montre la répartition de dés truqués ayant 3 faces 1, 5 faces 2 et une face 3.
    Le résultat final nous montre que lorsque l'on lance 2 de ces dés de 9 faces. En faisant
    la somme des coefficients, on obtient le nombre d'arrangement possible.  Dans le cas
    présent, on a donc $1 + 5 + 28 + 15 + 9$ c'est à dire $59$.  Cela nous permet de dire
    qu'il y a une chance sur 59 que la somme de ses 2 dés forme un 6 et 28 chance sur 59
    de former un 4.\\
    L'équation exprimé au début de ce point représente simplement le développement de 
    ce polynome.
    % TODO Robin (remarque)
%     Le raisonnement sur les polynômes est assez clair, mais l'explication est un peu confuse : 
%     l'idée est d'utiliser les fonctions génératrices afin de trouver le nombre de combinaisons relatives à la somem des dés.
%     « Le résultat final nous montre que lorsque l’on lance 2 de ces dés de 9 faces. » La phrase n'est pas complète. ;)
    
  \subsection{Faire un double}
    % TODO un nombre indéfinit de dés... toujours un double où tous les dés les mêmes ?
    Les règles du Monopoly stipulent que lorsque l'on fait 3 doubles à la suite, on est
    envoyé en prison.  Pour modéliser ce comportement via une chaîne de Markov, il va 
    falloir triplé le nombre d'état.  En effet, une case $i$ peut être visité après avoir
    fait 0 double, 1 double ou 2 double.  Si de cette case $i$ on refaire encore un double,
    on se retrouve en case prison.  Si par contre on fait un simple nombre, on se retrouve
    de nouveau sur la case $i$ ``zero double''.  Il est assez simple de se rendre compte de
    ça via la figure \ref{representation_double}.  Sur cette image, on peut donc voir en 
    rouge les déplacements fait grace à des doubles.  Ces 3 lignes rouges montre
    donc le déplacement d'un joueur qui aurait lancé les dés et fait consécutivement 3 doubles,
    à savoir ici: $1+1$, $2+2$ et $6+6$.  Ce dernière double le conduit directement en prison.
    Les flèches bleus montrent ce qu'il se passe lorsque l'on fait un simple déplacement (pas un double).
    Elles vont toutes vers la même plateau (celui où on a encore fait zero double).
    \begin{figure}[h]
      \centering
      \includegraphics[scale=0.4]{./Images/MonopolyVertical.png}
	\caption{Déplacement en cas de double}
	\label{representation_double}
    \end{figure}
    % TODO question: lorsque l'on a fait 2 doubles et qu'on a une carte chance qui nous déplace... On a
    % toujours 2 doubles à notre actif ou pas ?
    Pour savoir si un nombre est un double, il suffit de vérifier que le nombre est divisible
    par le nombre de dés.  Il faut cependant bien tenir compte du fait qu'il y a plusieurs
    moyen de former un nombre.  Par exemple, avec deux dés, il y a trois manières différentes
    de former un 4: $1+3$, $2+2$ et $3+1$.  Il y a donc 3 chance sur 36 de faire un 4 mais
    seulement une sur 36 de faire un double et 2 sur 36 de faire un simple 4 avec deux dés
    différents.
    Dans le point % TODO
    
  \subsection{Case prison}
    \label{case_prison}
    Les règles du Monopoly stipulent que l'on peut sortir de prison de plusieurs manières 
    différentes: soit via une carte chance, soit en payant, soit en faisant un double.
    Seule les deux dernières solutions seront utilisé dans cette modélisation.  En effet,
    avoir une carte chance ne dépend pas uniquement de l'état précédent et ne peut donc
    pas être représenté facilement avec les chaînes de Markov. Les règles indiquent 
    également que l'on ne peut rester que 3 tours maximum avant d'être obligé de payer.
    Afin de représenter ces différentes cas, la case prison sera ``triplée``.  On aura
    donc trois représentations de la case prison: au premier, second et troisième tour.
    La case ''aller en prison`` sera donc considérée comme une case prison de niveau 0 et
    n'aura qu'une seule arrête visant la case ''prison premier tour``.
    Afin d'être le plus précis possible, on va calculer la probabilité de faire un double.
    Comme vu dans la \fullref{repart_des}, il y a 36 cas possible lorsque l'on lance 
    2 dés à 6 faces.  On sait qu'il y a 6 doubles.  On a donc 6 chance sur 36 de faire un
    double et chaque double: $2$, $4$, $6$, $8$, $10$ et $12$ ont chacun une chance sur 36
    d'apparaitre.  Si on ne fait pas de double (dans 5 cas sur 6), on doit relancer les 
    dés (et donc avant ça, passer à la case prison ''suivante``).
    Chaque case ''prison`` (les 3 cases cités ci-dessus) auront donc 8 arrêtes différentes:
    \begin{itemize}
     \item Payer et sortir de prison;
     \item Faire un double (et avancer du résultat de ce double), il y a donc 6 choix possibles;
     \item Ne pas réussir à faire un double (et continuer attendre).
    \end{itemize}
    
  \subsection{Case ''Chance``}
    Les cases chances peuvent faire gagner de l'argent mais également déplacé les pions 
    présent sur le plateau de jeu.  C'est évidemment ce second comportement qui sera
    étudier ici.  Le Monopoly comporte 16 cartes chances ayant la répartition suivante:
    \begin{itemize}
     \item 8 cartes faisant référence à des payements;
     \item une carte ''sortir de prison``;
     \item 7 cartes faisant référence à un déplacement.
    \end{itemize}
    On peut donc en déduire que lorsqu'un joueur pioche une carte chance, il aura une 
    7 chance sur 16 de devoir déplacer son pion.  Ces déplacements sont les suivants:
    \begin{itemize}
     \item Reculer de 3 cases;
     \item Se rendre à la case départ;
     \item Aller en prison;
     \item Se rendre à la 11ème case (où 0 est le départ);
     \item Se rendre à la 15ème case;
     \item Se rendre à la 24ème case;
     \item Se rendre à la 36ème case (dernière case avant l'arrivée).
    \end{itemize}
    Dans les 9 autres cas on lancera simplement les dés.  Les cases chances ont donc 
    beaucoup d'arrêtes.
    
  \subsection{Case ''Caisse de communauté``}
    Les cartes ''Caisse de communauté`` sont plus axé sur l'aspect financier du jeu.
    Cependant 3 cartes provoques également des déplacements des pions.
    \begin{itemize}
     \item Se rendre à la case départ;
     \item Aller en prison;
     \item Se rendre sur le première case.
    \end{itemize}
    La modélisation des cartes ''caisse de communauté`` se fait de la même manière que 
    les cartes ''Chance``.
    
  \subsection{Calcul de l'état stationnaire}
    Comme vu dans le point \ref{etat_stationnaire}, il est possible de calculer
    la distribution stationnaire de chaque case du Monopoly.  Pour se faire, on va
    se basé sur une des méthodes décrite dans ce même point, à savoir simplifier la
    fonction de base:
    \begin{align*}
     wP &= w\\
     wP &= wI\\
     w(P-I) &= 0
    \end{align*}
    Où $w$ est le vecteur stationnaire que l'on cherche, $P$ est la matrice de 
    déplacement et $I$ est la matrice identité.  On peut également noté cette 
    equation de la façon suivante:
    $$(P-I)^{T} w^{T} = 0$$
    Qui sera plus simple à implémenté dans un langage informatique.\\
    % TODO expliquer pourquoi ce sera plus simple (résolution linéaire)
    On peut également rajouter une colonne de 1 permettant d'intégrer directement la 
    contrainte suivante dans l'équation:
    $$\sum\limits_{i \in w} i = 1$$
    Cette équation part du simple principe que le vecteur résultat sera la distribution 
    de probabilité de chaque état.  Il faut donc que leur somme corresponde à 1 vu 
    que l'on exprime la probabilité de se trouver sur tous les états accèssibles, il y
    a donc une probabilié 1 de se trouver sur les états présent dans le vecteur résultat 
    (plus d'informations dans le point \ref{etat_stationnaire}).
    \paragraph{Avec un exemple concret}
    Prenons la matrice de déplacement suivante:
    % TODO exemple très mauvais !!!  Ce n'est pas une chaine de markov !
    \begin{align*} 
      wP = w\\ 
      % === NEW LINE ===
      % > w
      \left( 
	\begin{array}{ccc}
	w_1 & w_2 & w_3
	\end{array} 
      \right) 
      % > p
      \left( 
	\begin{array}{ccc}
	1 & 0 & 1 \\
	2 & 0 & 0 \\
	0 & 1 & 3 
	\end{array} 
      \right)
      = 
      % > w
      \left( 
	\begin{array}{ccc}
	w_1 & w_2 & w_3
	\end{array} 
      \right)  
      \\
      % === NEW LINE ===
      % w 
      \left( 
	\begin{array}{c}
	w_1\\
	w_2\\
	w_3
	\end{array} 
      \right)^T
      % (
      \left(
        % P
	\left(
	\begin{array}{ccc}
	1 & 0 & 1 \\
	2 & 0 & 0 \\
	0 & 1 & 3 
	\end{array} 
	\right)
	-
	% I
	\left(
	\begin{array}{ccc}
	1 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1 
	\end{array} 
	\right)
      % )
      \right)
      = 0
      \\ 
      % === NEW LINE ===
      % w
      \left( 
	\begin{array}{ccc}
	w_1 & w_2 & w_3
	\end{array} 
      \right)
      % (P-I)
      \left( 
	\begin{array}{ccc}
	0 & 0 & 1 \\
	2 & -1 & 0 \\
	0 & 1 & 2 
	\end{array} 
      \right) 
      = 
      % 0
      \left( 
	\begin{array}{ccc}
	0 & 0 & 0
	\end{array} 
      \right)
      \\
      % === NEW LINE ===
      % (P-I)^T
      \left( 
	\begin{array}{ccc}
	0 & 0 & 1 \\
	2 & -1 & 0 \\
	0 & 1 & 2 
	\end{array} 
      \right)^T
      % w
      \left( 
	\begin{array}{c}
	w_1\\
	w_2\\
	w_3
	\end{array} 
      \right)
      = 
      % 0
      \left( 
	\begin{array}{c}
	0\\
	0\\
	0
	\end{array} 
      \right)
    \end{align*}
    On ajoute donc la colonne de 1:
    \begin{align*}
      \left( 
	\begin{array}{cccc}
	0 & 0 & 1 & 1 \\
	2 & -1 & 0 & 1 \\
	0 & 1 & 2 & 1
	\end{array} 
      \right)^T 
      \left( 
	\begin{array}{c}
	w_1\\
	w_2\\
	w_3
	\end{array} 
      \right)
      = 
      \left( 
	\begin{array}{c}
	0\\
	0\\
	0\\
	1
	\end{array} 
      \right)
    \end{align*}
    
    
  \subsection{Choix du langage}
    Pour modéliser le Monopoly, le langage Python a été choisi.  Il permet en effet
    d'avoir accès facilement à plusieurs librairies permettant de manipuler
    facilement des données.
    
    \subsubsection{Libraires utilisées}
      Pour manipuler plus facilement des matrices et résoudre les équations linéaire,
      la librairie ''numpy`` a été utilisé.  Concernant l'interface graphique, c'est
      la librairie ''Tkinter`` qui a été sélectionnée.
    
\section{Résultat}


\section{Conclusion}
  
  
%     ===== EXEMPLE =====
%     \begin{tikzpicture}
%       % Draw the states
%       \node[state,
% 	    text=yellow,
% 	    draw=none,
% 	    fill=gray!50!black] (s) {Sunny};
%       \node[state,
% 	    right=of s,
% 	    text=blue!30!white, 
% 	    draw=none, 
% 	    fill=gray!50!black] (r) {Rainy};
% 
%       % Connect the states with arrows
%       \draw[every loop]
% 	  (s) edge[bend right] node {} (r)
% 	  (r) edge[bend right] node {} (s)
% 	  (s) edge[bend right, auto=left]  node {0.6} (r)
% 	  (r) edge[bend right, auto=right] node {0.7} (s)
% 	  (s) edge[loop above]             node {0.4} (s)
% 	  (r) edge[loop above]             node {0.3} (r);
%     \end{tikzpicture}
  

\footnotesize
\nocite{*}
\bibliographystyle{apalike}
\bibliography{Rapport}


\end{document}